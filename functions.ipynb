{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e018cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from math import * \n",
    "import math\n",
    "import sympy as sy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "%matplotlib widget\n",
    "import trackpy as tp\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from scipy import integrate\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy import optimize\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib.widgets import SpanSelector\n",
    "from scipy.integrate import simpson\n",
    "from numpy import trapz\n",
    "\n",
    "# odr function from scipy package\n",
    "# is used to perform ODR regression\n",
    "from scipy import odr  \n",
    "from scipy.optimize import leastsq\n",
    "\n",
    "\n",
    "# --> Change globally the fonts of the plots:\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({ 'font.sans-serif':'Arial'})\n",
    "# to restore defaults use:    mpl.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9870d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used function in the program:\n",
    "def filt(df, var, low, high):\n",
    "    #filter function\n",
    "    return df[(df[var]>=low) & (df[var]<=high)]\n",
    "\n",
    "\n",
    "# make a grid\n",
    "def grid (start,end):\n",
    "    minor_ticks=np.linspace(start,end,end+1)\n",
    "    ax.set_xticks(minor_ticks,minor=True)\n",
    "    ax.set_yticks(minor_ticks,minor=True)\n",
    "    \n",
    "    major_ticks = np.linspace(start,int(end),int(end/5+1))\n",
    "    ax.set_yticks(major_ticks,major=True)\n",
    "    ax.set_xticks(major_ticks,major=True)\n",
    "    \n",
    "    ax.grid(which=\"minor\",alpha=0.3)\n",
    "    ax.grid(which = 'major',color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "    \n",
    "# Used sites:\n",
    "# https://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle\n",
    "# https://www.matheboard.de/archive/598910/thread.html\n",
    "\n",
    "\n",
    "def calc_average(l):\n",
    "    l = [x for x in l if str(x) != 'nan']\n",
    "    if len(l) > 0:\n",
    "        return np.mean(l)\n",
    "    else:\n",
    "        return 0\n",
    "      \n",
    "def plot_D_band(ax,y):\n",
    "    real_D_band = np.array(np.linspace(67,67*7,7))\n",
    "    sb =  real_D_band - 5\n",
    "    eb =  real_D_band + 5\n",
    "    borders = [[sb[j],eb[j]] for j in range(len(real_D_band))] \n",
    "    return [ax.fill_between(j,max(y),min(y),color = 'green',alpha = .2) for j in borders]\n",
    "\n",
    "def find_strings_containing_substring(strings, substring):\n",
    "    return [s for s in strings if substring in s]\n",
    "\n",
    "def resize_img(img, h, w):\n",
    "    hh=int(img.shape[0]/h)\n",
    "    ww=int(img.shape[1]/w)\n",
    "    imag=np.zeros([h, w])\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            imag[i,j]=np.sum(img[i*hh:(i+1)*hh, j*ww:(j+1)*ww])\n",
    "\n",
    "def psf_img_rec2(psf, df):\n",
    "    x=(df['Y']).values.astype(int) # 10 nm/pixel\n",
    "    y=(df['X']).values.astype(int)\n",
    "    #z=df['z_cor'].values\n",
    "    #N=df['N'].values\n",
    "    s=psf.shape\n",
    "    image=np.zeros([2000,2000])\n",
    "    for i in range(len(df)):\n",
    "        image[int(np.round(x[i]-(26))):int(np.round(x[i]+(25))) , \n",
    "              int(np.round(y[i]-(26))):int(np.round(y[i]+(25)))]+=psf\n",
    "    return image\n",
    "\n",
    "# Function to read CSV files with error handling\n",
    "def read_csv_file(file_name):\n",
    "    try:\n",
    "        return pd.read_csv(file_name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name}\")\n",
    "        return None\n",
    "    \n",
    "def cross(ax): # used for plotting\n",
    "    ax.axhline(y=0, xmin=0, xmax=1,color ='lightgrey')\n",
    "    ax.axvline(x=0, ymin=0, ymax=1,color ='lightgrey') \n",
    "    \n",
    "# Taken from https://scipython.com/blog/direct-linear-least-squares-fitting-of-an-ellipse/\n",
    "\n",
    "def fit_ellipse(x, y):\n",
    "    \"\"\"\n",
    "\n",
    "    Fit the coefficients a,b,c,d,e,f, representing an ellipse described by\n",
    "    the formula F(x,y) = ax^2 + bxy + cy^2 + dx + ey + f = 0 to the provided\n",
    "    arrays of data points x=[x1, x2, ..., xn] and y=[y1, y2, ..., yn].\n",
    "\n",
    "    Based on the algorithm of Halir and Flusser, \"Numerically stable direct\n",
    "    least squares fitting of ellipses'.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    D1 = np.vstack([x**2, x*y, y**2]).T\n",
    "    D2 = np.vstack([x, y, np.ones(len(x))]).T\n",
    "    S1 = D1.T @ D1\n",
    "    S2 = D1.T @ D2\n",
    "    S3 = D2.T @ D2\n",
    "    T = -np.linalg.inv(S3) @ S2.T\n",
    "    M = S1 + S2 @ T\n",
    "    C = np.array(((0, 0, 2), (0, -1, 0), (2, 0, 0)), dtype=float)\n",
    "    M = np.linalg.inv(C) @ M\n",
    "    eigval, eigvec = np.linalg.eig(M)\n",
    "    con = 4 * eigvec[0]* eigvec[2] - eigvec[1]**2\n",
    "    ak = eigvec[:, np.nonzero(con > 0)[0]]\n",
    "    return np.concatenate((ak, T @ ak)).ravel()\n",
    "\n",
    "\n",
    "def cart_to_pol(coeffs):\n",
    "    \"\"\"\n",
    "\n",
    "    Convert the cartesian conic coefficients, (a, b, c, d, e, f), to the\n",
    "    ellipse parameters, where F(x, y) = ax^2 + bxy + cy^2 + dx + ey + f = 0.\n",
    "    The returned parameters are x0, y0, ap, bp, e, phi, where (x0, y0) is the\n",
    "    ellipse centre; (ap, bp) are the semi-major and semi-minor axes,\n",
    "    respectively; e is the eccentricity; and phi is the rotation of the semi-\n",
    "    major axis from the x-axis.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # We use the formulas from https://mathworld.wolfram.com/Ellipse.html\n",
    "    # which assumes a cartesian form ax^2 + 2bxy + cy^2 + 2dx + 2fy + g = 0.\n",
    "    # Therefore, rename and scale b, d and f appropriately.\n",
    "    a = coeffs[0]\n",
    "    b = coeffs[1] / 2\n",
    "    c = coeffs[2]\n",
    "    d = coeffs[3] / 2\n",
    "    f = coeffs[4] / 2\n",
    "    g = coeffs[5]\n",
    "\n",
    "    den = b**2 - a*c\n",
    "    if den > 0:\n",
    "        raise ValueError('coeffs do not represent an ellipse: b^2 - 4ac must'\n",
    "                         ' be negative!')\n",
    "\n",
    "    # The location of the ellipse centre.\n",
    "    x0, y0 = (c*d - b*f) / den, (a*f - b*d) / den\n",
    "\n",
    "    num = 2 * (a*f**2 + c*d**2 + g*b**2 - 2*b*d*f - a*c*g)\n",
    "    fac = np.sqrt((a - c)**2 + 4*b**2)\n",
    "    # The semi-major and semi-minor axis lengths (these are not sorted).\n",
    "    ap = np.sqrt(num / den / (fac - a - c))\n",
    "    bp = np.sqrt(num / den / (-fac - a - c))\n",
    "\n",
    "    # Sort the semi-major and semi-minor axis lengths but keep track of\n",
    "    # the original relative magnitudes of width and height.\n",
    "    width_gt_height = True\n",
    "    if ap < bp:\n",
    "        width_gt_height = False\n",
    "        ap, bp = bp, ap\n",
    "\n",
    "    # The eccentricity.\n",
    "    r = (bp/ap)**2\n",
    "    if r > 1:\n",
    "        r = 1/r\n",
    "    e = np.sqrt(1 - r)\n",
    "\n",
    "    # The angle of anticlockwise rotation of the major-axis from x-axis.\n",
    "    if b == 0:\n",
    "        phi = 0 if a < c else np.pi/2\n",
    "    else:\n",
    "        phi = np.arctan((2.*b) / (a - c)) / 2\n",
    "        if a > c:\n",
    "            phi += np.pi/2\n",
    "    if not width_gt_height:\n",
    "        # Ensure that phi is the angle to rotate to the semi-major axis.\n",
    "        phi += np.pi/2\n",
    "    phi = phi % np.pi\n",
    "\n",
    "    return x0, y0, ap, bp, e, phi\n",
    "\n",
    "\n",
    "def get_ellipse_pts(params, npts=10000, tmin=0, tmax=2*np.pi):\n",
    "    \"\"\"\n",
    "    Return npts points on the ellipse described by the params = x0, y0, ap,\n",
    "    bp, e, phi for values of the parametric variable t between tmin and tmax.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x0, y0, ap, bp, e, phi = params\n",
    "    # A grid of the parametric variable, t.\n",
    "    t = np.linspace(tmin, tmax, npts)\n",
    "    x = x0 + ap * np.cos(t) * np.cos(phi) - bp * np.sin(t) * np.sin(phi)\n",
    "    y = y0 + ap * np.cos(t) * np.sin(phi) + bp * np.sin(t) * np.cos(phi)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def calc_height(locS_c,upper_cutoff=None,def_para=None):\n",
    "    locS_c = locS_c.sort_values('X')\n",
    "    \n",
    "    # Set default value inside the function\n",
    "    if upper_cutoff is None:\n",
    "        upper_cutoff = max(locS_c['Y']) / 2\n",
    "        \n",
    "#     upper_cutoff1 = np.mean(locS_c['Y'])\n",
    "#     upper_cutoff2 = max(locS_c['Y'])/2\n",
    "\n",
    "#     if upper_cutoff1 < upper_cutoff2:\n",
    "#         upper_cutoff = upper_cutoff2\n",
    "#     else:\n",
    "#         upper_cutoff = upper_cutoff1\n",
    "\n",
    "    STORM_Data_upper_half = locS_c[locS_c['Y']>upper_cutoff]\n",
    "\n",
    "    # make the fit for the upper data points\n",
    "    upper_fit = np.polyfit(STORM_Data_upper_half['X'],STORM_Data_upper_half['Y'],2)\n",
    "    x_upper_fit = np.linspace(-100,100,1000)\n",
    "    y_upper_fit = np.polyval(upper_fit,x_upper_fit)\n",
    "\n",
    "    # save the upper point:\n",
    "    height_polyfit = max(y_upper_fit)\n",
    "    x_STORM_fit_max = x_upper_fit[list(y_upper_fit).index(max(y_upper_fit))]\n",
    "\n",
    "\n",
    "\n",
    "    # Binning the Data like in AFM:\n",
    "    Data_n_STORM = filt(locS_c,'X',-120,120)\n",
    "    Data_n_STORM = Data_n_STORM.sort_values('X')\n",
    "\n",
    "    # bin the data along the X-axis\n",
    "    X_range = max(Data_n_STORM['X']) + abs(min(Data_n_STORM['X']))\n",
    "    bin_width = 20\n",
    "\n",
    "    num_of_bins = int(X_range/bin_width)\n",
    "    c_data = pd.cut(Data_n_STORM['X'],bins=num_of_bins) # bins with equal width\n",
    "    Data_n_STORM['bin'] = c_data\n",
    "    Data_n_STORM_mean = Data_n_STORM.groupby(['bin']).mean()\n",
    "    Data_n_STORM_mean = Data_n_STORM_mean.sort_values('X')\n",
    "\n",
    "    STORM_mean_height = list(Data_n_STORM_mean['Y'])\n",
    "\n",
    "    # Height takes the max of the binned data points\n",
    "    height_bin = round(max(STORM_mean_height),2)\n",
    "    x_STORM_fib_height = list(Data_n_STORM_mean['X'])[STORM_mean_height.index(max(STORM_mean_height))]\n",
    "\n",
    "\n",
    "    STORM_sw_H_n,x_max_sw_n,y_max_sw_n = sliding_win_n(locS_c,n_ws,overlap_n)\n",
    "    sliding_window_height = y_max_sw_n\n",
    "    # sliding window binning datapoints\n",
    "    \n",
    "    \n",
    "    # Simple Height approach:\n",
    "    fig_STORM_cross_section_topfit, ax1=plt.subplots()\n",
    "    ax1.scatter(STORM_Data_upper_half['X'],STORM_Data_upper_half['Y'],s=0.8,alpha=0.9,c='b') \n",
    "    ax1.scatter(locS_c['X'],locS_c['Y'], s=0.5, alpha=0.8,c='grey')\n",
    "    ax1.plot(x_upper_fit,y_upper_fit)\n",
    "    ax1.plot([x_STORM_fit_max,x_STORM_fit_max],[0,height_polyfit],color='blue',\n",
    "                label = f'height_polyfit: {round(height_polyfit,2)}')\n",
    "    ax1.set_xlabel(\"X / nm\") # X-axis label\n",
    "    ax1.set_ylabel(\"Z / nm\") # Y-axis label\n",
    "    ax1.axis('equal')\n",
    "\n",
    "    # ax1.plot([-200,200],[upper_cutoff1,upper_cutoff1],c='magenta')\n",
    "    # ax1.plot([-200,200],[upper_cutoff2,upper_cutoff2],c='cyan')\n",
    "\n",
    "    ax1.scatter(Data_n_STORM_mean['X'], STORM_mean_height,color='r',s=10) \n",
    "    ax1.plot([x_STORM_fib_height,x_STORM_fib_height],[0,height_bin],\n",
    "             color='r',label=f'binned height: {height_bin} nm')\n",
    "    ax1.axhline(color='k',alpha=0.2)\n",
    "    ax1.axvline(color='k',alpha=0.2)\n",
    "    \n",
    "    # Plot the sliding window binning:\n",
    "    ax1.scatter(STORM_sw_H_n[0],STORM_sw_H_n[1],c='g',marker='+',\n",
    "            label = f'Nr of datapoints per bin: {n_ws},'+\n",
    "            f' overlap: {int(overlap_n*100)}%, H: {round(y_max_sw_n,2)}',s=40)\n",
    "    ax1.plot([x_max_sw_n,x_max_sw_n],[0,y_max_sw_n],c='g')\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax1.set_title(f'{def_para}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "#     fig_STORM_cross_section_topfit.savefig(results_folder+f'fig_STORM_cross_section_topfit_{def_para}.png',dpi=600)\n",
    "\n",
    "    return height_polyfit,height_bin,sliding_window_height,STORM_Data_upper_half\n",
    "\n",
    "def filter_effect(fm, Nf, LLRf, epsf, msf,locS_c,locS):\n",
    "    fig, ax =plt.subplots(2,2,figsize=(8,8))\n",
    "    locS_c = locS_c[locS_c['N']>Nf]  \n",
    "    ax[0][0].scatter(locS['X'],locS['Y'], s=0.5, alpha=0.5,c='grey')\n",
    "    ax[0][0].scatter(locS_c['X'],locS_c['Y'], s=1, alpha=0.8,c='C0')\n",
    "\n",
    "\n",
    "    locS_c = locS_c[locS_c['LLR']<LLRf] \n",
    "    ax[0][1].scatter(locS['X'],locS['Y'], s=0.5, alpha=0.5,c='grey')\n",
    "    ax[0][1].scatter(locS_c['X'],locS_c['Y'], s=1, alpha=0.8,c='C0')\n",
    "\n",
    "\n",
    "    locS_c = locS_c.sort_values('X')\n",
    "    x_locS = locS_c.loc[:, ['X','Y']].values\n",
    "    dbscanS = DBSCAN(eps = epsf,\n",
    "                     min_samples = msf).fit(x_locS) # fitting the model\n",
    "    labelsS = dbscanS.labels_# getting the labels\n",
    "    locS_c['cluster2']=labelsS\n",
    "    locS_c = locS_c[locS_c['cluster2']>=0]\n",
    "\n",
    "    # filter for clustering\n",
    "    ax[1][0].scatter(locS['X'],locS['Y'], s=0.5, alpha=0.5,c='grey')\n",
    "    ax[1][0].scatter(x_locS[:, 0], x_locS[:,1], c = labelsS, s=1) # plotting the clusters\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the heights with fitting polynome:\n",
    "#     upper_cutoff_poly = locS_c.copy()\n",
    "#     upper_cutoff_poly = filt(upper_cutoff_poly,'X',-10,10)\n",
    "#     upper_cutoff_poly = min(upper_cutoff_poly['Y'])\n",
    "    upper_cutoff_poly = 100\n",
    "    x_fit,h_poly,x_u_fit,y_u_fit,S_D_u_half = calc_height_polynome(locS_c,upper_cutoff_poly)\n",
    "\n",
    "    # fit the polynome\n",
    "    ax[1][1].scatter(S_D_u_half['X'],S_D_u_half['Y'],s=0.8,alpha=0.9,c='C0') \n",
    "    ax[1][1].scatter(locS_c['X'],locS_c['Y'], s=0.5, alpha=0.5,c='grey')\n",
    "    ax[1][1].plot(x_u_fit,y_u_fit,color='red')\n",
    "    ax[1][1].plot([x_fit,x_fit],[0,h_poly],color='black',\n",
    "                label = f'height_polyfit: {round(h_poly,2)}')\n",
    "\n",
    "    ax[0][0].set_title(f'N: {Nf}')\n",
    "    ax[0][1].set_title(f'LLR: {LLRf}')\n",
    "    ax[1][0].set_title(f'eps:{epsf}, cluster min: {msf}')\n",
    "    ax[1][1].set_title(f'Height: {np.round(h_poly,2)} nm')\n",
    "\n",
    "    ax[0][0].set_xlabel(\"X / nm\"),ax[0][0].set_ylabel(\"Z / nm\")\n",
    "    ax[0][1].set_xlabel(\"X / nm\"),ax[0][1].set_ylabel(\"Z / nm\")\n",
    "    ax[1][0].set_xlabel(\"X / nm\"),ax[1][0].set_ylabel(\"Z / nm\")\n",
    "    ax[1][1].set_xlabel(\"X / nm\"),ax[1][1].set_ylabel(\"Z / nm\")\n",
    "\n",
    "    ax[0][0].axis('equal'), ax[0][1].axis('equal')\n",
    "    ax[1][0].axis('equal'), ax[1][1].axis('equal')\n",
    "\n",
    "    ax[1][1].axhline(color='k',alpha=0.2)\n",
    "    ax[1][1].axvline(color='k',alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filter_folder+f'/filter_N{Nf}_LLR{LLRf}_eps{epsf}_msf{msf}_H{h_poly}.png',dpi=600)\n",
    "    new_row = {'fm':fm,'N':Nf,'LLR':LLRf,'eps':epsf,'min':msf,'H':h_poly}\n",
    "    return new_row\n",
    "\n",
    "def calc_height_polynome(locS_c,upper_cutoff=None):\n",
    "    # Set default value inside the function\n",
    "    if upper_cutoff is None:\n",
    "        upper_cutoff = max(locS_c['Y']) / 2\n",
    "    STORM_Data_upper_half = locS_c[locS_c['Y']>upper_cutoff]\n",
    "\n",
    "    # make the fit for the upper data points\n",
    "    upper_fit = np.polyfit(STORM_Data_upper_half['X'],STORM_Data_upper_half['Y'],2)\n",
    "    x_upper_fit = np.linspace(-100,100,1000)\n",
    "    y_upper_fit = np.polyval(upper_fit,x_upper_fit)\n",
    "\n",
    "    # save the upper point:\n",
    "    height_polyfit = max(y_upper_fit)\n",
    "    x_STORM_fit_max = x_upper_fit[list(y_upper_fit).index(max(y_upper_fit))]\n",
    "    return x_STORM_fit_max,height_polyfit,x_upper_fit,y_upper_fit,STORM_Data_upper_half\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e2e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used functions for binning:\n",
    "\n",
    "## Use a sliding windw to make the binning:\n",
    "   \n",
    "# Define a sliding window with the beginning a, the end b and the windw size ws\n",
    "# Then define how much the first window overlaps with the next defined as overlap\n",
    "# Filter out the data in that window and calculate whatever you are interested in\n",
    "\n",
    "# overlap = 0.5 by default\n",
    "# 0.2 would be 20 % overlap of two windows\n",
    "# 1 would be no overlap and 0 is not a valid input\n",
    "\n",
    "def sliding_win(df, ws, overlap):\n",
    "    start, end = min(df['X']), max(df['X'])\n",
    "    res = []\n",
    "    a = start\n",
    "    step = ws * (1 - overlap)  # Step size considering overlap\n",
    "    \n",
    "    print(a,end)\n",
    "    while a < end:\n",
    "        b = a + ws\n",
    "        dfs = filt(df, 'X', a, b)\n",
    "        if len(dfs) > 0:  # Ensure there is data in the window\n",
    "            H = np.median(dfs['Y'])  # Assuming 'Y' is the column of interest\n",
    "            res.append([np.mean([a, b]), H])\n",
    "        a += step  # Move the window\n",
    "    y_values = [r[1] for r in res]\n",
    "    max_index = y_values.index(max(y_values))\n",
    "    res_max = res[max_index]\n",
    "    \n",
    "    x_values = [k[0] for k in res]\n",
    "    y_values = [k[1] for k in res]\n",
    "    res = [x_values,y_values]\n",
    "    return res,res_max[0],res_max[1]\n",
    "    # return all binned datapoints and also where the max is\n",
    "    \n",
    "def sliding_win_n(df, n, overlap):\n",
    "    \n",
    "#     Applies a sliding window over the dataframe with a fixed number of data points per window.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): DataFrame containing 'X' and 'Y' columns.\n",
    "#     n (int): Number of data points in each window.\n",
    "#     overlap (float): Overlap fraction (0 to 1), where 0 means no overlap, 1 means full overlap.\n",
    "\n",
    "#     Returns:\n",
    "#     list: List of [mean_x, median_y] for each window.\n",
    "#     float: x-value where Y is maximum.\n",
    "#     float: maximum Y value.\n",
    "    res = []\n",
    "    step = int(n * (1 - overlap))  # Calculate step size in terms of data points\n",
    "\n",
    "    if step < 1:  # Avoid infinite loops\n",
    "        step = 1\n",
    "\n",
    "    for i in range(0, len(df) - n + 1, step):\n",
    "        window = df.iloc[i:i+n]  # Select n data points\n",
    "        mean_x = np.mean(window['X'])  # Compute mean X value for the window\n",
    "        median_y = np.median(window['Y'])  # Compute median Y value for the window\n",
    "        res.append([mean_x, median_y])\n",
    "\n",
    "    # Find the max Y value and its corresponding X\n",
    "    y_values = [r[1] for r in res]\n",
    "    max_index = y_values.index(max(y_values))\n",
    "    res_max = res[max_index]\n",
    "    \n",
    "    x_values = [k[0] for k in res]\n",
    "    y_values = [k[1] for k in res]\n",
    "    res = [x_values,y_values]\n",
    "    return res, res_max[0], res_max[1]  # Return all bins and max location\n",
    "\n",
    "# Perform \"normal\" binning without any overlap:\n",
    "def bin_data_by_x(df, bin_width):\n",
    "#     Bins the data along the X-axis into equal-width bins, calculates the median for each bin, \n",
    "#     and returns the binned data along with the corresponding Y values.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): DataFrame with 'X' and 'Y' columns.\n",
    "#     bin_width (float): Width of each bin.\n",
    "\n",
    "#     Returns:\n",
    "#     DataFrame: DataFrame with the median values for each bin.\n",
    "#     list: List of Y values (median of each bin).\n",
    "    \n",
    "    df = df.sort_values('X')\n",
    "    \n",
    "    # Calculate the range of X values\n",
    "    X_range = max(df['X']) - min(df['X'])\n",
    "    \n",
    "    # Determine the number of bins based on X_range and bin_width\n",
    "    num_of_bins = int(X_range / bin_width)\n",
    "    \n",
    "    # Create the bins along the X-axis\n",
    "    c_data = pd.cut(df['X'], bins=num_of_bins)\n",
    "    \n",
    "    # Add the 'bin' column to the DataFrame\n",
    "    df['bin'] = c_data\n",
    "    \n",
    "    # Group by the 'bin' column and calculate the median of Y for each bin\n",
    "    df_mean = df.groupby(['bin']).median()\n",
    "    \n",
    "    # Extract the median Y values\n",
    "    max_y_index = df_mean['Y'].idxmax() \n",
    "    mean_height_x = df_mean.loc[max_y_index, 'X'] \n",
    "    mean_height = df_mean.loc[max_y_index, 'Y']\n",
    "    \n",
    "    return df_mean, mean_height_x, mean_height\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c7478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For calculating the error:\n",
    "def sliding_win_height(df, n, overlap):\n",
    "    \n",
    "#     Applies a sliding window over the dataframe with a fixed number of data points per window.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): DataFrame containing 'X' and 'Y' columns.\n",
    "#     n (int): Number of data points in each window.\n",
    "#     overlap (float): Overlap fraction (0 to 1), where 0 means no overlap, 1 means full overlap.\n",
    "\n",
    "#     Returns:\n",
    "#     list: List of [mean_x, median_y] for each window.\n",
    "#     float: x-value where Y is maximum.\n",
    "#     float: maximum Y value.\n",
    "    res = []\n",
    "    step = int(n * (1 - overlap))  # Calculate step size in terms of data points\n",
    "\n",
    "    if step < 1:  # Avoid infinite loops\n",
    "        step = 1\n",
    "\n",
    "    for i in range(0, len(df) - n + 1, step):\n",
    "        window = df.iloc[i:i+n]  # Select n data points\n",
    "        mean_x = np.mean(window['X'])  # Compute mean X value for the window\n",
    "        median_y = np.median(window['Y'])  # Compute median Y value for the window\n",
    "        res.append([mean_x, median_y])\n",
    "\n",
    "    # Find the max Y value and its corresponding X\n",
    "    y_values = [r[1] for r in res]\n",
    "    max_index = y_values.index(max(y_values))\n",
    "    res_max = res[max_index]\n",
    "    \n",
    "    x_values = [k[0] for k in res]\n",
    "    y_values = [k[1] for k in res]\n",
    "    res = [x_values,y_values]\n",
    "    \n",
    "    STORM_sw_H_n,x_max_sw_n,y_max_sw_n = res,res_max[0], res_max[1]\n",
    "    return STORM_sw_H_n, x_max_sw_n, y_max_sw_n  # Return all bins and max location\n",
    "\n",
    "\n",
    "def calc_error(T_test,n_loc,overlap):\n",
    "#     T_test...profile with X and Y values\n",
    "#     n_loc...number of locs in sliding window\n",
    "#     overlap...number of overlapping locs in sliding window\n",
    "    \n",
    "    error_height_boot = [] # bootstrapping\n",
    "    error_height_resa = [] # subsampling\n",
    "\n",
    "    num_of_datapoints = len(T_test)\n",
    "    low, high = 0, num_of_datapoints  # Change these to your desired range\n",
    "\n",
    "    \n",
    "    # Bootstrapping\n",
    "    for k in range(10000):\n",
    "\n",
    "        # Generate random numbers in the range [low, high)\n",
    "        r_num_boot = np.random.choice(range(low, high), \n",
    "                                      size = num_of_datapoints, replace=True)\n",
    "   \n",
    "        T_test_resample_boot = T_test.iloc[r_num_boot]\n",
    "        T_test_resample_boot = T_test_resample_boot.sort_values('X')\n",
    "        H_n_boot, x_n_boot, y_max_boot = sliding_win_height(T_test_resample_boot,n_loc,overlap)\n",
    "        error_height_boot += [y_max_boot]\n",
    "    \n",
    "    # Subsampling\n",
    "    for j in range(1000):\n",
    "        r_num_resa = np.random.choice(range(low, high), \n",
    "                                      size = int(num_of_datapoints/2), \n",
    "                                      replace=False)\n",
    "        \n",
    "        T_test_resample_resa = T_test.iloc[r_num_resa]\n",
    "        T_test_resample_resa = T_test_resample_resa.sort_values('X')\n",
    "        H_n_resa, x_n_resa, y_max_resa = sliding_win_height(T_test_resample_resa,n_loc,overlap)\n",
    "        error_height_resa += [y_max_resa]\n",
    "\n",
    "    med_boot = np.mean(error_height_boot)\n",
    "    sdt_boot = np.std(error_height_boot)\n",
    "\n",
    "    med_resa = np.mean(error_height_resa)\n",
    "    sdt_resa = np.std(error_height_resa)\n",
    "\n",
    "    return error_height_boot,med_boot,sdt_boot,error_height_resa,med_resa,sdt_resa\n",
    "\n",
    "\n",
    "\n",
    "def extract_n(df_plot,H_AFM_compare):\n",
    "    # make a linear fit through the datapoints:\n",
    "    x_fit = df_plot['refractive_index']\n",
    "    y_fit = df_plot['sliding_window_height']\n",
    "    fit_p = np.polyfit(x_fit,y_fit,1)\n",
    "    x_n = np.linspace(min(x_fit),max(x_fit),100)\n",
    "    y_n = np.polyval(fit_p,x_n)\n",
    "\n",
    "    # Calculate the intersection:\n",
    "    n = (H_AFM_compare-fit_p[1])/fit_p[0]\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f667e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec80288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156db7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd52db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d3f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee1246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
